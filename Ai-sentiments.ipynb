{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33e57fcc",
   "metadata": {},
   "source": [
    "## Notes and next steps\n",
    "\n",
    "This notebook performs sentiment analysis on Amazon product reviews from `Reviews.csv`.\n",
    "\n",
    "- It provides both a rule-based sentiment score (VADER) and a transformer-based score (DistilBERT SST-2).\n",
    "- By default the notebook processes a sample (to stay fast). Set `PROCESS_FULL = True` to run on the whole file (requires more time/memory).\n",
    "- Outputs a CSV `reviews_sentiment_results.csv` with original columns plus sentiment columns.\n",
    "\n",
    "If you need GPU acceleration or a different transformer model, change the `HF_MODEL` variable in the model cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b911e9ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# NLP imports\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mvaderSentiment\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvaderSentiment\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentimentIntensityAnalyzer\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# Setup: install required packages (uncomment to run in notebook environment)\n",
    "# Note: for local execution on Windows PowerShell, run these commands in a terminal if the notebook cannot install packages directly.\n",
    "# !pip install pandas numpy matplotlib seaborn tqdm nltk scikit-learn transformers sentencepiece torch vaderSentiment\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# NLP imports\n",
    "import nltk\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from transformers import pipeline\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk_available = True\n",
    "\n",
    "# Config\n",
    "DATA_PATH = r\"c:\\Users\\asiqi\\OneDrive\\Desktop\\Collage\\SEM_6\\AI_Analysics\\archive (3)\\Reviews.csv\"\n",
    "OUTPUT_CSV = 'reviews_sentiment_results.csv'\n",
    "PROCESS_FULL = False  # Set True to run on entire file (may be slow/high memory)\n",
    "SAMPLE_SIZE = 2000  # when PROCESS_FULL=False, use this many random reviews\n",
    "HF_MODEL = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "\n",
    "print('Notebook setup complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807477dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Data loading (handles large files by reservoir sampling when PROCESS_FULL=False)\n",
    "import random\n",
    "\n",
    "def sample_reviews(path, sample_size=2000, usecols=None, chunksize=10000, seed=42):\n",
    "    \"\"\"Reservoir sample rows from a potentially large CSV file without loading entire file into memory.\n",
    "    Returns a DataFrame of sampled rows (as strings by default).\n",
    "    \"\"\"\n",
    "    rng = random.Random(seed)\n",
    "    reservoir = []\n",
    "    total = 0\n",
    "    for chunk in pd.read_csv(path, usecols=usecols, chunksize=chunksize, iterator=True, encoding='utf-8', dtype=str, low_memory=False):\n",
    "        for _, row in chunk.iterrows():\n",
    "            total += 1\n",
    "            if len(reservoir) < sample_size:\n",
    "                reservoir.append(row)\n",
    "            else:\n",
    "                j = rng.randrange(total)\n",
    "                if j < sample_size:\n",
    "                    reservoir[j] = row\n",
    "    if len(reservoir) == 0:\n",
    "        return pd.DataFrame(columns=usecols)\n",
    "    df = pd.DataFrame(reservoir)\n",
    "    return df\n",
    "\n",
    "# Which columns we'll use\n",
    "USECOLS = ['Id','ProductId','UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Score','Time','Summary','Text']\n",
    "\n",
    "if PROCESS_FULL:\n",
    "    print('Loading full dataset (this may take a long time)...')\n",
    "    df = pd.read_csv(DATA_PATH, usecols=USECOLS, encoding='utf-8', low_memory=False)\n",
    "else:\n",
    "    print(f'Sampling {SAMPLE_SIZE} reviews from the dataset...')\n",
    "    df = sample_reviews(DATA_PATH, sample_size=SAMPLE_SIZE, usecols=USECOLS)\n",
    "\n",
    "print('Loaded rows:', len(df))\n",
    "\n",
    "# quick peek\n",
    "if len(df) > 0:\n",
    "    display(df.head())\n",
    "else:\n",
    "    print('No rows loaded. Check DATA_PATH and USECOLS.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc6cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Preprocessing\n",
    "import re\n",
    "\n",
    "def clean_text(s):\n",
    "    if pd.isna(s):\n",
    "        return ''\n",
    "    # remove multiple whitespace and newlines\n",
    "    s = str(s)\n",
    "    s = re.sub(r\"\\s+\", ' ', s).strip()\n",
    "    return s\n",
    "\n",
    "# create a unified 'review_text' field by combining Summary and Text\n",
    "df['Summary'] = df['Summary'].fillna('').astype(str)\n",
    "df['Text'] = df['Text'].fillna('').astype(str)\n",
    "df['review_text'] = (df['Summary'] + '. ' + df['Text']).map(clean_text)\n",
    "\n",
    "# drop empty text rows\n",
    "before = len(df)\n",
    "df = df[df['review_text'].str.len() > 0].reset_index(drop=True)\n",
    "after = len(df)\n",
    "print(f'Removed {before-after} empty reviews. Remaining {after} reviews.')\n",
    "\n",
    "# show sample\n",
    "if len(df) > 0:\n",
    "    display(df[['Id','Score','review_text']].head())\n",
    "\n",
    "# short sanity checks\n",
    "print('Score value counts:')\n",
    "print(df['Score'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a227638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) VADER sentiment (rule-based)\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_scores(text):\n",
    "    return analyzer.polarity_scores(text)\n",
    "\n",
    "vader_out = df['review_text'].map(vader_scores)\n",
    "\n",
    "vader_df = pd.DataFrame(list(vader_out))\n",
    "df = pd.concat([df.reset_index(drop=True), vader_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# label from compound score\n",
    "\n",
    "def compound_to_label(c):\n",
    "    if c >= 0.05:\n",
    "        return 'positive'\n",
    "    elif c <= -0.05:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "df['vader_label'] = df['compound'].map(compound_to_label)\n",
    "print('VADER labeling complete')\n",
    "display(df[['Id','Score','compound','vader_label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Transformer-based sentiment (Hugging Face pipeline)\n",
    "print('Loading HF pipeline (this will download model the first time)')\n",
    "classifier = pipeline('sentiment-analysis', model=HF_MODEL, device=-1)\n",
    "\n",
    "# batch predictions\n",
    "batch_size = 32\n",
    "labels = []\n",
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    batch_texts = df['review_text'].iloc[i:i+batch_size].tolist()\n",
    "    out = classifier(batch_texts)\n",
    "    labels.extend(out)\n",
    "\n",
    "# classifier returns list of dicts with 'label' and 'score'\n",
    "label_df = pd.DataFrame(labels)\n",
    "# map label names to 'positive'/'negative' if necessary\n",
    "label_df['label'] = label_df['label'].str.lower().map(lambda s: 'positive' if 'pos' in s else ('negative' if 'neg' in s else s))\n",
    "label_df = label_df.rename(columns={'label': 'hf_label', 'score': 'hf_score'})\n",
    "\n",
    "# attach to df\n",
    "label_df = label_df.reset_index(drop=True)\n",
    "df = pd.concat([df.reset_index(drop=True), label_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print('Transformer sentiment complete')\n",
    "display(df[['Id','Score','hf_label','hf_score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c7c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Evaluation & visualization\n",
    "# Create a simple label from the numeric star Score (1-2 negative, 3 neutral, 4-5 positive)\n",
    "def score_to_label(s):\n",
    "    try:\n",
    "        s = float(s)\n",
    "    except Exception:\n",
    "        return 'neutral'\n",
    "    if s <= 2:\n",
    "        return 'negative'\n",
    "    elif s == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'positive'\n",
    "\n",
    "if 'Score' in df.columns:\n",
    "    df['star_label'] = df['Score'].map(score_to_label)\n",
    "\n",
    "# confusion counts\n",
    "print('VADER vs Stars:')\n",
    "print(pd.crosstab(df['star_label'], df['vader_label']))\n",
    "print('\\nHuggingFace vs Stars:')\n",
    "print(pd.crosstab(df['star_label'], df['hf_label']))\n",
    "\n",
    "# simple distribution plots\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.countplot(x='vader_label', data=df)\n",
    "plt.title('VADER label counts')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.countplot(x='hf_label', data=df)\n",
    "plt.title('HF label counts')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# show some disagreement examples\n",
    "mismatch = df[df['vader_label'] != df['hf_label']].sample(n=min(5, max(0, len(df[df['vader_label'] != df['hf_label']]))))\n",
    "if len(mismatch) > 0:\n",
    "    display(mismatch[['Id','Score','review_text','vader_label','hf_label','compound','hf_score']])\n",
    "else:\n",
    "    print('No disagreements found in sample')\n",
    "\n",
    "# Save results\n",
    "save_path = OUTPUT_CSV\n",
    "print('Saving results to', save_path)\n",
    "df.to_csv(save_path, index=False)\n",
    "print('Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d6b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install VADER Sentiment if not already installed\n",
    "!pip install vaderSentiment\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the reviews CSV file\n",
    "# Assuming the CSV has a column named 'review' containing the customer feedback text.\n",
    "# If your column name is different, replace 'review' with the actual column name.\n",
    "df = pd.read_csv('reviews.csv')\n",
    "\n",
    "# Display the first few rows to verify the data\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Initialize the VADER sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment scores and classify sentiment\n",
    "def get_sentiment(text):\n",
    "    scores = sia.polarity_scores(text)\n",
    "    compound = scores['compound']\n",
    "    if compound >= 0.05:\n",
    "        return 'Positive', scores\n",
    "    elif compound <= -0.05:\n",
    "        return 'Negative', scores\n",
    "    else:\n",
    "        return 'Neutral', scores\n",
    "\n",
    "# Apply sentiment analysis to each review\n",
    "df[['sentiment', 'scores']] = df['review'].apply(lambda x: pd.Series(get_sentiment(x)))\n",
    "\n",
    "# Extract individual scores into separate columns\n",
    "df['negative'] = df['scores'].apply(lambda x: x['neg'])\n",
    "df['neutral'] = df['scores'].apply(lambda x: x['neu'])\n",
    "df['positive'] = df['scores'].apply(lambda x: x['pos'])\n",
    "df['compound'] = df['scores'].apply(lambda x: x['compound'])\n",
    "\n",
    "# Drop the temporary 'scores' column\n",
    "df.drop('scores', axis=1, inplace=True)\n",
    "\n",
    "# Display the updated dataframe with sentiment analysis\n",
    "print(\"\\nUpdated dataframe with sentiment analysis:\")\n",
    "print(df.head())\n",
    "\n",
    "# Perform basic analysis\n",
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "average_compound = df['compound'].mean()\n",
    "\n",
    "print(\"\\nSentiment Counts:\")\n",
    "print(sentiment_counts)\n",
    "print(f\"\\nAverage Compound Score: {average_compound:.4f}\")\n",
    "\n",
    "# Interpretation of average compound score\n",
    "if average_compound >= 0.05:\n",
    "    print(\"Overall sentiment is Positive.\")\n",
    "elif average_compound <= -0.05:\n",
    "    print(\"Overall sentiment is Negative.\")\n",
    "else:\n",
    "    print(\"Overall sentiment is Neutral.\")\n",
    "\n",
    "# Visualize the sentiment distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sentiment_counts.plot(kind='bar', color=['green', 'red', 'blue'])\n",
    "plt.title('Distribution of Customer Sentiments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Visualize the average scores\n",
    "avg_scores = df[['negative', 'neutral', 'positive']].mean()\n",
    "plt.figure(figsize=(8, 6))\n",
    "avg_scores.plot(kind='bar', color=['red', 'blue', 'green'])\n",
    "plt.title('Average Sentiment Scores')\n",
    "plt.xlabel('Score Type')\n",
    "plt.ylabel('Average Score')\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
